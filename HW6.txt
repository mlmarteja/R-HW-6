#dataset
head(mtcars)
print(mtcars)
mtcars


##v engine = 0
##straight engine =1
##new column
mtcars$vs2 <-ifelse(mtcars$vs == 0,"V engine","straight engine")
mtcars
print(mtcars)
head(mtcars)


############data testing##############
indexes <- sample(2,nrow(mtcars),replace = T,prob = c(0.2,0.8))
indexes

training <- mtcars[indexes == 1,]
test <- mtcars[indexes == 2,]
training
test

###########naive payes################
install.packages("naivebayes")
library(naivebayes)

model<- naive_bayes(vs2~.,data=training,usekernel = T)
plot(model)

p <- predict(model,test)
table(p,test$vs2)



#######logistic regression##########
###a classification algorithm that calculates 
###the probability of fitting into one category
###will be a logistic curve

glm.fit<- glm(as.factor(vs2) ~ cyl+ disp + hp+drat +wt + qsec + vs + am + gear+carb+mpg,data = training, family = binomial)
summary(glm.fit)

glm.probs <- predict(glm.fit, test, type = "response")
table(glm.probs,test$vs2)

glm.pred<- ifelse(glm.probs > 0.5, "V Engine","Straight Engine")
attach(test)
table(glm.pred,vs2)

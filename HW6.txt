#dataset
head(mtcars)
print(mtcars)
mtcars


##v engine = no
##straight engine = yes
##new column
mtcars$vs2 <-ifelse(mtcars$vs == 0,"no","yes")
mtcars
print(mtcars)


############data testing##############
indexes <- sample(2,nrow(mtcars),replace = T,prob = c(0.2,0.8))
indexes

training <- mtcars[indexes == 1,]
test <- mtcars[indexes == 2,]
training
test

###########naive payes################
install.packages("naivebayes")
library(naivebayes)

model<- naive_bayes(vs2~.,data=training,usekernel = T)
plot(model)

p <- predict(model,test)
table(p,test$mpg)



#######logistic regression##########
###a classification algorithm that calculates 
###the probability of fitting into one category
###will be a logistic curve

glm.fit<- glm(as.factor(vs2) ~ cyl+ disp + hp+drat +wt + qsec + vs + am + gear+carb+mpg,data = training, family = binomial)
summary(glm.fit)

glm.probs <- predict(glm.fit, test, type = "response")
glm.probs[1:5]
